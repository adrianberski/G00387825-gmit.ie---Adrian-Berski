{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The analysis of a real-world phenomenon for Programming for Data Analysis.<h1>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Introductory remarks.\n",
    "\n",
    "\n",
    "A data set shall be interpreted as a collection of statistical data which is usually included in a tabulated form. It is important to mention that most often, the columns correspond to the observed statistical characteristics and each row describes one observation from the sample. The matrix cell values describe the implementation of variable data in subsequent observations.\n",
    "\n",
    "\n",
    "The purpose of this project is to research the data set and write documentation and code (in Python programming language) to investigate it. It`s important to mention that Data scientist can be interpreted as a process of experimentation and exploration to find answers. Therefore, data science pursues the various scientific method. The data science process includes steps particular to working with large, digital datasets. Before the real-world phenomenon was choose, every scientist needs to follow crucial steps:\n",
    "\n",
    "- Determine the necessary data;\n",
    "- Get the data;\n",
    "- Clean and organize the data;\n",
    "- Explore the data;\n",
    "- Model the data;\n",
    "- Communicate findings.\n",
    "\n",
    "Every of each modeling and synthesise have to include the above steps of analysis. In this project three aspects are taken into account: data scope, variable relationships and data context. \n",
    "\n",
    "\n",
    "\n",
    "## Determine the necessary data.\n",
    "In thisstate of affairs, it has been used the United States Cities Database (uscities.csv). This is up-to-date (November 18th 2020) database of United States cities and towns. \n",
    "The second set is the user_data.csv which includes information about my users, such as: education, age and location. As an example of a hypothesis which proofs that my data are neccesary to collect is a question: is there a correlation between a user’s location (rural or urban) and their age? Based on provided data, it can be defined what is rural and urban location as data sets don`t detrmine that information. \n",
    "Determination process helps to apporve or dispartove particular hypotesis and helps to define how much data are needed to collect. To do this, Sample size calculators (available online) are the best tools. They shows: Margin of error, Confidence level, Population size Likely sample proportion.\n",
    "As data sets for this project have more than 200 entries, they met criertia.\n",
    "\n",
    "\n",
    "\n",
    "## Get the data.\n",
    "This project requires passive data collection, which means they are already exist. It uses data from the Simple Maps website contains a United States Cities database (the proper link has been included in the List of sourxes.). As it was mentioned above, the project requires to cross-reference of 2 provided data sets. The 2 files: uscities.csv and user_data.csv are attached to repository. \n",
    "\n",
    "\n",
    "## Clean and organize the data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               city        education  age\n0      Brooklyn, NY          college   31\n1      Brooklyn, NY  graduate degree   31\n2      Brooklyn, NY  graduate degree   32\n3      Brooklyn, NY          college   37\n4      Brooklyn, NY          college   21\n..              ...              ...  ...\n95    Baltimore, MD          college   32\n96    Baltimore, MD          college   33\n97  Los Angeles, CA          college   34\n98  Los Angeles, CA          college   35\n99  Los Angeles, CA          college   36\n\n[100 rows x 3 columns]\n           city   city_ascii state_id    state_name  county_fips  county_name  \\\n0      New York     New York       NY      New York        36061     New York   \n1   Los Angeles  Los Angeles       CA    California         6037  Los Angeles   \n2       Chicago      Chicago       IL      Illinois        17031         Cook   \n3         Miami        Miami       FL       Florida        12086   Miami-Dade   \n4        Dallas       Dallas       TX         Texas        48113       Dallas   \n..          ...          ...      ...           ...          ...          ...   \n95       Denton       Denton       TX         Texas        48121       Denton   \n96      Madison      Madison       WI     Wisconsin        55025         Dane   \n97         Reno         Reno       NV        Nevada        32031       Washoe   \n98   Harrisburg   Harrisburg       PA  Pennsylvania        42043      Dauphin   \n99  Little Rock  Little Rock       AR      Arkansas         5119      Pulaski   \n\n        lat       lng  population  density   source  military  incorporated  \\\n0   40.6943  -73.9249    18713220  10715.0  polygon     False          True   \n1   34.1139 -118.4068    12750807   3276.0  polygon     False          True   \n2   41.8373  -87.6862     8604203   4574.0  polygon     False          True   \n3   25.7839  -80.2102     6445545   5019.0  polygon     False          True   \n4   32.7936  -96.7662     5743938   1526.0  polygon     False          True   \n..      ...       ...         ...      ...      ...       ...           ...   \n95  33.2176  -97.1419      457177    567.0  polygon     False          True   \n96  43.0826  -89.3931      447245   1263.0  polygon     False          True   \n97  39.5497 -119.8483      445020    907.0  polygon     False          True   \n98  40.2752  -76.8843      442289   2343.0  polygon     False          True   \n99  34.7256  -92.3576      439815    634.0  polygon     False          True   \n\n               timezone  ranking  \\\n0      America/New_York        1   \n1   America/Los_Angeles        1   \n2       America/Chicago        1   \n3      America/New_York        1   \n4       America/Chicago        1   \n..                  ...      ...   \n95      America/Chicago        2   \n96      America/Chicago        2   \n97  America/Los_Angeles        2   \n98     America/New_York        2   \n99      America/Chicago        2   \n\n                                                 zips          id  \n0   11229 11226 11225 11224 11222 11221 11220 1138...  1840034016  \n1   90291 90293 90292 91316 91311 90037 90031 9000...  1840020491  \n2   60018 60649 60641 60640 60643 60642 60645 6064...  1840000494  \n3   33129 33125 33126 33127 33128 33149 33144 3314...  1840015149  \n4   75287 75098 75233 75254 75251 75252 75253 7503...  1840019440  \n..                                                ...         ...  \n95  76207 76205 76201 76208 76209 76210 76259 7620...  1840019390  \n96  53706 53704 53705 53703 53726 53792 53719 5371...  1840002915  \n97  89521 89523 89439 89503 89502 89501 89506 8950...  1840020121  \n98  17101 17102 17103 17104 17120 17110 17105 1710...  1840001288  \n99  72211 72210 72212 72223 72209 72202 72201 7220...  1840015509  \n\n[100 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "#importing relevant libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the 2 CSV files and create the DataFrames:\n",
    "user_data = pd.read_csv(\"user_data.csv\")\n",
    "uscities = pd.read_csv(\"uscities.csv\")\n",
    "\n",
    "# becasue of Pana library the set can be transform to a table(showing 100 records):\n",
    "\n",
    "print(user_data.head(100))\n",
    "print(uscities.head(100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## List of sources.\n",
    "\n",
    "***\n",
    "\n",
    "<b> 1) DOCUMENTS AND REPORTS.</b>\n",
    "\n",
    "Datasets: \n",
    "<http://www.cs.toronto.edu/~delve/data/>\n",
    "\n",
    "UCI Machine Learning Repository:\n",
    "<http://archive.ics.uci.edu/ml/datasets/Iris>\n",
    "\n",
    "NumPy Documentation:\n",
    "<https://numpy.org/doc/stable/reference/random/>\n",
    "\n",
    "NumPy v1.19 Manual:\n",
    "<https://numpy.org/doc/stable/index.html>\n",
    "\n",
    "NumPy in general:\n",
    "<https://numpy.org/>\n",
    "\n",
    "\n",
    "<b> 2) ARTICLES, MONOGRAPHS, STUDIES.</b>\n",
    "\n",
    "Encyclopaedia Britannica: \n",
    "<http://www.britannica.com/>\n",
    "\n",
    "Schweppes J., How to Think Write and Cite – key skills for Irish Law, Dublin 2011.\n",
    "\n",
    "Waugh S., Extending and benchmarking Cascade-Correlation, Tasmania 1995.\n",
    "\n",
    "Internet Resources: \n",
    "\n",
    "<https://www.w3schools.com/python/numpy_random.asp>\n",
    "\n",
    "<https://www.geeksforgeeks.org/numpy-random-rand-python/>\n",
    "\n",
    "<https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html>\n",
    "\n",
    "<https://www.markdownguide.org/getting-started/>\n",
    "\n",
    "<https://medium.com/@ingeh/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed>\n",
    "\n",
    "<https://github.com/>\n",
    "\n",
    "<https://en.wikipedia.org/wiki/Triangular_distribution>\n",
    "\n",
    "<https://gitter.im/GMIT-Python-Learners-2019/community>\n",
    "\n",
    "<https://docs.python.org/3/tutorial/>\n",
    "\n",
    "<https://leanpub.com/pyprog/read>\n",
    "\n",
    "<https://www.codecademy.com/courses/data-visualization-python/lessons/matplotlib-i/exercises/introduction-matplotlib-i>\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}