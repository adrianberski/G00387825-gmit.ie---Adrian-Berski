{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The analysis of a real-world phenomenon for Programming for Data Analysis.<h1>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Introductory remarks.\n",
    "\n",
    "\n",
    "A data set shall be interpreted as a collection of statistical data which is usually included in a tabulated form. It is important to mention that most often, the columns correspond to the observed statistical characteristics and each row describes one observation from the sample. The matrix cell values describe the implementation of variable data in subsequent observations.\n",
    "\n",
    "\n",
    "The purpose of this project is to research the data set and write documentation and code (in Python programming language) to investigate it. It`s important to mention that Data scientist can be interpreted as a process of experimentation and exploration to find answers. Therefore, data science pursues the various scientific method. The data science process includes steps particular to working with large, digital datasets. Before the real-world phenomenon was choose, every scientist needs to follow crucial steps:\n",
    "\n",
    "- Determine the necessary data;\n",
    "- Get the data;\n",
    "- Clean and organize the data;\n",
    "- Explore the data;\n",
    "- Model the data;\n",
    "- Communicate findings.\n",
    "\n",
    "Every of each modeling and synthesise have to include the above steps of analysis. In this project three aspects are taken into account: data scope, variable relationships and data context. \n",
    "\n",
    "\n",
    "\n",
    "## Determine the necessary data.\n",
    "In thisstate of affairs, it has been used the United States Cities Database (uscities.csv). This is up-to-date (November 18th 2020) database of United States cities and towns. \n",
    "The second set is the user_data.csv which includes information about my users, such as: education, age and location. As an example of a hypothesis which proofs that my data are neccesary to collect is a question: is there a correlation between a userâ€™s location (rural or urban) and their age? Based on provided data, it can be defined what is rural and urban location as data sets don`t detrmine that information. \n",
    "Determination process helps to apporve or dispartove particular hypotesis and helps to define how much data are needed to collect. To do this, Sample size calculators (available online) are the best tools. They shows: Margin of error, Confidence level, Population size Likely sample proportion.\n",
    "As data sets for this project have more than 200 entries, they met criertia.\n",
    "\n",
    "\n",
    "\n",
    "## Get the data.\n",
    "This project requires passive data collection, which means they are already exist. It uses data from the Simple Maps website contains a United States Cities database (the proper link has been included in the List of sourxes.). As it was mentioned above, the project requires to cross-reference of 2 provided data sets. The 2 files: uscities.csv and user_data.csv are attached to repository. \n",
    "\n",
    "\n",
    "## Clean and organize the data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              city        education  age\n0     Brooklyn, NY          college   31\n1     Brooklyn, NY  graduate degree   31\n2     Brooklyn, NY  graduate degree   32\n3     Brooklyn, NY          college   37\n4     Brooklyn, NY          college   21\n5       Austin, TX          college   25\n6      Oakland, CA  graduate degree   29\n7   Pittsburgh, PA          college   29\n8   Pittsburgh, PA          college   27\n9   Pittsburgh, PA  graduate degree   28\n10        Ames, IA          college   31\n11      Albany, NY  graduate degree   31\n12   Lancaster, PA          college   31\n13        Reno, NV      high school   31\n14     Houston, TX      high school   31\n"
     ]
    }
   ],
   "source": [
    "#importing relevant libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the 2 CSV files and create the DataFrames:\n",
    "user_data = pd.read_csv(\"user_data.csv\")\n",
    "pop_data = pd.read_csv(\"pop_data.csv\")\n",
    "\n",
    "# becasue of Panda library the set can be transform to a table(showing 15records):\n",
    "\n",
    "print(user_data.head(15))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              city        education  age  population_proper\n0     Brooklyn, NY          college   31          2629150.0\n1     Brooklyn, NY  graduate degree   31          2629150.0\n2     Brooklyn, NY  graduate degree   32          2629150.0\n3     Brooklyn, NY          college   37          2629150.0\n4     Brooklyn, NY          college   21          2629150.0\n5       Austin, TX          college   25           947890.0\n6       Austin, TX  graduate degree   22           947890.0\n7      Oakland, CA  graduate degree   29           420005.0\n8   Pittsburgh, PA          college   29           303625.0\n9   Pittsburgh, PA          college   27           303625.0\n10  Pittsburgh, PA  graduate degree   28           303625.0\n11  Pittsburgh, PA  graduate degree   36           303625.0\n12        Ames, IA          college   31            66191.0\n13      Albany, NY  graduate degree   31            98111.0\n14   Lancaster, PA          college   31            59218.0\n"
     ]
    }
   ],
   "source": [
    "#now I need to merge both files in order to analyse the abobe hypothesis. I will use Panda`s modulde: merging \n",
    "new_df = pd.merge(user_data, pop_data)\n",
    "\n",
    "\n",
    "#now I am testing my code:\n",
    "print(new_df.head(15))\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "#as the code is working I have to analyse size of the population. I will do that by new field 'location' which classifieds rural or urban place.\n",
    "\n",
    "new_df.loc[new_df.population_proper < 100000, \"location\"] = \"rural\"\n",
    "new_df.loc[new_df.population_proper >= 100000, \"location\"] = \"urban\"\n",
    "\n",
    "print(new_df.head(15))\n",
    "\n",
    "# so now I can see apprpriate relations \n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 145,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              city        education  age  population_proper location\n0     Brooklyn, NY          college   31          2629150.0    urban\n1     Brooklyn, NY  graduate degree   31          2629150.0    urban\n2     Brooklyn, NY  graduate degree   32          2629150.0    urban\n3     Brooklyn, NY          college   37          2629150.0    urban\n4     Brooklyn, NY          college   21          2629150.0    urban\n5       Austin, TX          college   25           947890.0    urban\n6       Austin, TX  graduate degree   22           947890.0    urban\n7      Oakland, CA  graduate degree   29           420005.0    urban\n8   Pittsburgh, PA          college   29           303625.0    urban\n9   Pittsburgh, PA          college   27           303625.0    urban\n10  Pittsburgh, PA  graduate degree   28           303625.0    urban\n11  Pittsburgh, PA  graduate degree   36           303625.0    urban\n12        Ames, IA          college   31            66191.0    rural\n13      Albany, NY  graduate degree   31            98111.0    rural\n14   Lancaster, PA          college   31            59218.0    rural\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## Explore the data.\n",
    "The data has been organized and defined. Exploring data process provides proper understanding how the data work and help to determine if any changes are required. \n",
    "It can be done by teo iots not doc yet !!!\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}